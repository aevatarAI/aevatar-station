name: PR Performance Benchmarks

on:
  push:
    branches:
      - 'feature/**'
    paths:
      - 'station/benchmark/**'
      - 'station/src/**'
      - '.github/workflows/**'
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
    paths:
      - 'station/benchmark/**'
      - 'station/src/**'
      - '.github/workflows/**'
  workflow_dispatch:
    inputs:
      broadcast_args:
        description: JSON for BroadcastLatencyBenchmark params
        required: false
        default: '{"subscribers":30,"publishers":1,"eps":5,"duration":20,"warmup":5}'
      latency_args:
        description: JSON for LatencyBenchmark params
        required: false
        default: '{"maxConcurrency":8,"duration":30,"warmup":5,"eps":10}'
      thresholds:
        description: JSON thresholds for benchmarks
        required: false
        default: '{"broadcast":{"avgMs":80,"p95Ms":150,"successRate":0.95,"throughputFactor":0.9},"latency":{"p95Ms":120,"p99Ms":220,"processedRatio":0.98,"throughputFactor":0.9}}'

concurrency:
  group: perf-pr-${{ github.ref }}
  cancel-in-progress: false

jobs:
  benchmarks:
    name: Run Performance Benchmarks
    runs-on: ubuntu-latest
    # Skip draft PRs, but allow manual workflow_dispatch and other events
    if: ${{ github.event_name != 'pull_request' || github.event.pull_request.draft == false }}
    timeout-minutes: 30
    env:
      # Threshold defaults (overridden by workflow_dispatch parsing step)
      BCAST_AVG_MS: '80'
      BCAST_P95_MS: '150'
      BCAST_SUCCESS_RATE: '0.95'
      BCAST_THROUGHPUT_FACTOR: '0.9'
      LAT_P95_MS: '120'
      LAT_P99_MS: '220'
      LAT_PROCESSED_RATIO: '0.98'
      LAT_THROUGHPUT_FACTOR: '0.9'
      # Param defaults (overridden by workflow_dispatch parsing step)
      BCAST_SUBS: '30'
      BCAST_PUBS: '1'
      BCAST_EPS: '5'
      BCAST_DURATION: '20'
      BCAST_WARMUP: '5'
      LAT_MAX_CONCURRENCY: '8'
      LAT_DURATION: '30'
      LAT_WARMUP: '5'
      LAT_EPS: '10'

    services:
      mongodb:
        image: mongo:7
        ports:
          - 27017:27017
        options: >-
          --health-cmd "mongosh --eval 'db.adminCommand(\"ping\")'"
          --health-interval 10s --health-timeout 5s --health-retries 10
      zookeeper:
        image: bitnami/zookeeper:3.9
        ports:
          - 2181:2181
        env:
          ALLOW_ANONYMOUS_LOGIN: 'yes'
      kafka:
        image: bitnami/kafka:3.7
        ports:
          - 9092:9092
        env:
          KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181
          ALLOW_PLAINTEXT_LISTENER: 'yes'
          KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: 'true'
          KAFKA_LISTENERS: PLAINTEXT://:9092
          KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup .NET SDKs (9 and 8)
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: |
            9.0.x
            8.0.x

      - name: Show dotnet info
        run: dotnet --info

      - name: Install jq, curl, netcat
        run: sudo apt-get update && sudo apt-get install -y jq curl netcat-openbsd

      - name: Parse workflow_dispatch JSON inputs (if provided)
        if: ${{ github.event_name == 'workflow_dispatch' }}
        shell: bash
        run: |
          echo "broadcast_args=${{ toJson(inputs.broadcast_args) }}"
          echo "latency_args=${{ toJson(inputs.latency_args) }}"
          echo "thresholds=${{ toJson(inputs.thresholds) }}"

          # Guard empty inputs
          B_JSON='${{ inputs.broadcast_args }}'
          L_JSON='${{ inputs.latency_args }}'
          T_JSON='${{ inputs.thresholds }}'

          if [ -n "$B_JSON" ]; then
            export BCAST_SUBS=$(echo "$B_JSON" | jq -r '.subscribers // empty') || true
            export BCAST_PUBS=$(echo "$B_JSON" | jq -r '.publishers // empty') || true
            export BCAST_EPS=$(echo "$B_JSON" | jq -r '.eps // empty') || true
            export BCAST_DURATION=$(echo "$B_JSON" | jq -r '.duration // empty') || true
            export BCAST_WARMUP=$(echo "$B_JSON" | jq -r '.warmup // empty') || true
          fi

          if [ -n "$L_JSON" ]; then
            export LAT_MAX_CONCURRENCY=$(echo "$L_JSON" | jq -r '.maxConcurrency // empty') || true
            export LAT_DURATION=$(echo "$L_JSON" | jq -r '.duration // empty') || true
            export LAT_WARMUP=$(echo "$L_JSON" | jq -r '.warmup // empty') || true
            export LAT_EPS=$(echo "$L_JSON" | jq -r '.eps // empty') || true
          fi

          if [ -n "$T_JSON" ]; then
            export BCAST_AVG_MS=$(echo "$T_JSON" | jq -r '.broadcast.avgMs // empty') || true
            export BCAST_P95_MS=$(echo "$T_JSON" | jq -r '.broadcast.p95Ms // empty') || true
            export BCAST_SUCCESS_RATE=$(echo "$T_JSON" | jq -r '.broadcast.successRate // empty') || true
            export BCAST_THROUGHPUT_FACTOR=$(echo "$T_JSON" | jq -r '.broadcast.throughputFactor // empty') || true
            export LAT_P95_MS=$(echo "$T_JSON" | jq -r '.latency.p95Ms // empty') || true
            export LAT_P99_MS=$(echo "$T_JSON" | jq -r '.latency.p99Ms // empty') || true
            export LAT_PROCESSED_RATIO=$(echo "$T_JSON" | jq -r '.latency.processedRatio // empty') || true
            export LAT_THROUGHPUT_FACTOR=$(echo "$T_JSON" | jq -r '.latency.throughputFactor // empty') || true
          fi

          # Persist to GITHUB_ENV if set
          for v in BCAST_SUBS BCAST_PUBS BCAST_EPS BCAST_DURATION BCAST_WARMUP LAT_MAX_CONCURRENCY LAT_DURATION LAT_WARMUP LAT_EPS \
                   BCAST_AVG_MS BCAST_P95_MS BCAST_SUCCESS_RATE BCAST_THROUGHPUT_FACTOR LAT_P95_MS LAT_P99_MS LAT_PROCESSED_RATIO LAT_THROUGHPUT_FACTOR; do
            if [ -n "${!v}" ] && [ "${!v}" != "null" ]; then echo "$v=${!v}" >> $GITHUB_ENV; fi
          done

      - name: Wait for MongoDB (TCP)
        shell: bash
        run: |
          for i in {1..60}; do
            if nc -z localhost 27017; then echo "MongoDB port open"; break; fi; sleep 2; done
          nc -z localhost 27017 || (echo "MongoDB not reachable" && exit 1)

      - name: Wait for Kafka (simple socket check)
        shell: bash
        run: |
          for i in {1..60}; do
            if nc -z localhost 9092; then echo "Kafka port open"; break; fi; sleep 2; done

      - name: Restore and build projects
        run: |
          dotnet restore station/src/Aevatar.Silo/Aevatar.Silo.csproj
          dotnet restore station/benchmark/BroadcastLatencyBenchmark/BroadcastLatencyBenchmark.csproj
          dotnet restore station/benchmark/LatencyBenchmark/LatencyBenchmark.csproj
          dotnet build -c Release station/src/Aevatar.Silo/Aevatar.Silo.csproj
          dotnet build -c Release station/benchmark/BroadcastLatencyBenchmark/BroadcastLatencyBenchmark.csproj
          dotnet build -c Release station/benchmark/LatencyBenchmark/LatencyBenchmark.csproj

      - name: Start Silo
        shell: bash
        run: |
          nohup dotnet run -c Release --project station/src/Aevatar.Silo/Aevatar.Silo.csproj > silo.log 2>&1 &
          echo $! > silo.pid

      - name: Wait for Silo readiness
        shell: bash
        run: |
          for i in {1..60}; do
            if curl -fsS http://localhost:8081/health/ready >/dev/null; then echo "Silo ready"; break; fi; sleep 2; done
          curl -fsS http://localhost:8081/health/ready || (echo "Silo not ready" && exit 1)

      - name: Run BroadcastLatencyBenchmark
        shell: bash
        run: |
          set -e
          dotnet run -c Release --project station/benchmark/BroadcastLatencyBenchmark/BroadcastLatencyBenchmark.csproj -- \
            --subscriber-count ${BCAST_SUBS} \
            --publisher-count ${BCAST_PUBS} \
            --events-per-second ${BCAST_EPS} \
            --duration ${BCAST_DURATION} \
            --warmup-duration ${BCAST_WARMUP} \
            --output-file broadcast-latency-results.json

      - name: Run LatencyBenchmark
        shell: bash
        run: |
          set -e
          dotnet run -c Release --project station/benchmark/LatencyBenchmark/LatencyBenchmark.csproj -- \
            --max-concurrency ${LAT_MAX_CONCURRENCY} \
            --events-per-second ${LAT_EPS} \
            --duration ${LAT_DURATION} \
            --warmup-duration ${LAT_WARMUP} \
            --output-file latency-results.json

      - name: Parse and check thresholds - Broadcast
        id: check_broadcast
        shell: bash
        run: |
          set -e
          test -f broadcast-latency-results.json || (echo "Missing broadcast-latency-results.json" && exit 1)
          jq '.' broadcast-latency-results.json > /dev/null || (echo "Invalid broadcast JSON" && exit 1)
          jq -e '.Results | length > 0' broadcast-latency-results.json > /dev/null || (echo "Broadcast results are empty" && exit 1)
          jq -r '
            .Results[0] as $r
            | $expected := ($r.TotalEventsSent * ($r.SubscriberCount // 0))
            | $successRate := (if $expected>0 then ($r.TotalEventsProcessed / $expected) else 0 end)
            | $throughput := (if $r.ActualDurationSeconds>0 then ($r.TotalEventsProcessed / $r.ActualDurationSeconds) else 0 end)
            | $expectedTp := (($r.PublisherCount // 0) * ($r.EventsPerSecond // 0))
            | {
                successRate: $successRate,
                throughput: $throughput,
                avg: $r.AverageLatencyMs,
                p95: $r.P95LatencyMs,
                expectedThroughput: $expectedTp
              }' broadcast-latency-results.json > broadcast_metrics.json

          sr=$(jq -r '.successRate' broadcast_metrics.json)
          tp=$(jq -r '.throughput' broadcast_metrics.json)
          avg=$(jq -r '.avg' broadcast_metrics.json)
          p95=$(jq -r '.p95' broadcast_metrics.json)
          etp=$(jq -r '.expectedThroughput' broadcast_metrics.json)

          echo "Broadcast metrics: successRate=$sr throughput=$tp avg=$avg p95=$p95 expectedThroughput=$etp"

          fail=0
          awk -v a="$sr" -v b="$BCAST_SUCCESS_RATE" 'BEGIN{ if (a+0 < b+0) exit 1 }' || { echo "❌ Broadcast successRate below $BCAST_SUCCESS_RATE"; fail=1; }
          if [ "${etp}" != "null" ] && [ "${etp}" != "0" ]; then
            awk -v a="$tp" -v b="$etp" -v f="$BCAST_THROUGHPUT_FACTOR" 'BEGIN{ if (a+0 < b*f) exit 1 }' || { echo "❌ Broadcast throughput below factor $BCAST_THROUGHPUT_FACTOR of expected"; fail=1; }
          fi
          awk -v a="$avg" -v b="$BCAST_AVG_MS" 'BEGIN{ if (a+0 > b+0) exit 1 }' || { echo "❌ Broadcast avg latency above $BCAST_AVG_MS ms"; fail=1; }
          awk -v a="$p95" -v b="$BCAST_P95_MS" 'BEGIN{ if (a+0 > b+0) exit 1 }' || { echo "❌ Broadcast P95 latency above $BCAST_P95_MS ms"; fail=1; }

          if [ "$fail" -ne 0 ]; then
            echo "Broadcast thresholds not met"; exit 1; fi

      - name: Parse and check thresholds - Latency
        id: check_latency
        shell: bash
        run: |
          set -e
          test -f latency-results.json || (echo "Missing latency-results.json" && exit 1)
          jq '.' latency-results.json > /dev/null || (echo "Invalid latency JSON" && exit 1)
          jq -e '.Results | length > 0' latency-results.json > /dev/null || (echo "Latency results are empty" && exit 1)
          jq -r '
            .Results | max_by(.ConcurrencyLevel) as $r
            | $expectedTp := (($r.ConcurrencyLevel // 0) * ($r.EventsPerSecond // 0))
            | $processedRatio := (if $r.TotalEventsSent>0 then ($r.TotalEventsProcessed / $r.TotalEventsSent) else 0 end)
            | {
                success: ($r.Success // false),
                throughput: ($r.ActualThroughput // 0),
                p95: ($r.P95LatencyMs // 0),
                p99: ($r.P99LatencyMs // 0),
                processedRatio: $processedRatio,
                expectedThroughput: $expectedTp
              }' latency-results.json > latency_metrics.json

          succ=$(jq -r '.success' latency_metrics.json)
          tp=$(jq -r '.throughput' latency_metrics.json)
          p95=$(jq -r '.p95' latency_metrics.json)
          p99=$(jq -r '.p99' latency_metrics.json)
          pratio=$(jq -r '.processedRatio' latency_metrics.json)
          etp=$(jq -r '.expectedThroughput' latency_metrics.json)

          echo "Latency metrics: success=$succ throughput=$tp p95=$p95 p99=$p99 processedRatio=$pratio expectedThroughput=$etp"

          fail=0
          if [ "$succ" != "true" ]; then echo "❌ Latency result marked unsuccessful"; fail=1; fi
          if [ "${etp}" != "null" ] && [ "${etp}" != "0" ]; then
            awk -v a="$tp" -v b="$etp" -v f="$LAT_THROUGHPUT_FACTOR" 'BEGIN{ if (a+0 < b*f) exit 1 }' || { echo "❌ Latency throughput below factor $LAT_THROUGHPUT_FACTOR of expected"; fail=1; }
          fi
          awk -v a="$p95" -v b="$LAT_P95_MS" 'BEGIN{ if (a+0 > b+0) exit 1 }' || { echo "❌ Latency P95 above $LAT_P95_MS ms"; fail=1; }
          awk -v a="$p99" -v b="$LAT_P99_MS" 'BEGIN{ if (a+0 > b+0) exit 1 }' || { echo "❌ Latency P99 above $LAT_P99_MS ms"; fail=1; }
          awk -v a="$pratio" -v b="$LAT_PROCESSED_RATIO" 'BEGIN{ if (a+0 < b+0) exit 1 }' || { echo "❌ Latency processed ratio below $LAT_PROCESSED_RATIO"; fail=1; }

          if [ "$fail" -ne 0 ]; then
            echo "Latency thresholds not met"; exit 1; fi

      - name: Write Job Summary
        if: always()
        shell: bash
        run: |
          echo "### Performance Benchmarks" >> $GITHUB_STEP_SUMMARY
          echo "- Broadcast and Latency benchmarks executed" >> $GITHUB_STEP_SUMMARY
          if [ -f broadcast_metrics.json ]; then
            echo "\n**Broadcast (key metrics)**" >> $GITHUB_STEP_SUMMARY
            jq -r 'to_entries | map("- **\(.key)**: \(.value)") | .[]' broadcast_metrics.json >> $GITHUB_STEP_SUMMARY
          fi
          if [ -f latency_metrics.json ]; then
            echo "\n**Latency (key metrics)**" >> $GITHUB_STEP_SUMMARY
            jq -r 'to_entries | map("- **\(.key)**: \(.value)") | .[]' latency_metrics.json >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            broadcast-latency-results.json
            latency-results.json
            broadcast_metrics.json
            latency_metrics.json
            silo.log

      - name: Stop Silo
        if: always()
        shell: bash
        run: |
          if [ -f silo.pid ]; then kill $(cat silo.pid) || true; fi

